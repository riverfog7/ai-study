{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from __future__ import annotations\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from typing import Optional, Union, List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import torch\n",
    "\n",
    "GRADIO_URL='https://3702090156a07c96e0.gradio.live'\n",
    "\n",
    "dataset_base = Path('dataset')\n",
    "advertising_base = dataset_base / 'advertising'\n",
    "memes_base = dataset_base / 'memes'\n",
    "poems_base = dataset_base / 'poems'\n",
    "recipie_base = dataset_base / 'recipie'\n",
    "mixed_base = dataset_base / 'mixed'\n",
    "\n",
    "meme_images = [val for val in memes_base.glob(\"*\") if 'source' not in str(val)]\n",
    "advertising_images = [val for val in advertising_base.glob(\"*\") if 'source' not in str(val)]\n",
    "poem_images = [val for val in poems_base.glob(\"*\") if 'source' not in str(val)]\n",
    "recipie_images = [val for val in recipie_base.glob(\"*\") if 'source' not in str(val)]\n",
    "mixed_images = [val for val in mixed_base.glob(\"**/*\") if 'txt' not in str(val) and val.is_file()]"
   ],
   "id": "9522a81ea2d466ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_cnt = 20\n",
    "delete_images = set()\n",
    "if len(poem_images) > sample_cnt:\n",
    "    poem_images_sampled = random.sample(poem_images, min(sample_cnt, len(poem_images)))\n",
    "    to_delete_poem = set(poem_images) - set(poem_images_sampled)\n",
    "    delete_images = delete_images.union(to_delete_poem)\n",
    "if len(advertising_images) > sample_cnt:\n",
    "    advertising_images_sampled = random.sample(advertising_images, min(sample_cnt, len(advertising_images)))\n",
    "    to_delete_advertising = set(advertising_images) - set(advertising_images_sampled)\n",
    "    delete_images = delete_images.union(to_delete_advertising)\n",
    "if len(meme_images) > sample_cnt:\n",
    "    meme_images_sampled = random.sample(meme_images, min(sample_cnt, len(meme_images)))\n",
    "    to_delete_meme = set(meme_images) - set(meme_images_sampled)\n",
    "    delete_images = delete_images.union(to_delete_meme)\n",
    "if len(recipie_images) > sample_cnt:\n",
    "    recipie_images_sampled = random.sample(recipie_images, min(sample_cnt, len(recipie_images)))\n",
    "    to_delete_recipie = set(recipie_images) - set(recipie_images_sampled)\n",
    "    delete_images = delete_images.union(to_delete_recipie)\n",
    "\n",
    "for img in delete_images:\n",
    "    os.remove(img)"
   ],
   "id": "c14631d18ed0cebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import tempfile\n",
    "import os\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "from gradio_client import Client\n",
    "\n",
    "\n",
    "class MiniGPT4Client:\n",
    "    def __init__(self, gradio_url: str, download_files: bool = False):\n",
    "        self.client = Client(gradio_url, download_files=download_files)\n",
    "        self.chatbot: List[List[Optional[str]]] = []\n",
    "        self.image_path: Optional[str] = None\n",
    "        self._tmp_files: List[str] = []\n",
    "\n",
    "    def _to_json_file(self, obj: Union[list, dict]) -> str:\n",
    "        fd, path = tempfile.mkstemp(suffix=\".json\")\n",
    "        os.close(fd)\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(obj, f, ensure_ascii=False)\n",
    "        self._tmp_files.append(path)\n",
    "        return path\n",
    "\n",
    "    def _normalize_chatbot(self, x) -> List[List[Optional[str]]]:\n",
    "        if isinstance(x, str) and os.path.exists(x):\n",
    "            with open(x, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        if isinstance(x, list):\n",
    "            return x\n",
    "        return []\n",
    "\n",
    "    def upload_image(self, image_path: str) -> str:\n",
    "        self.client.predict(image_path, \"\", fn_index=0)\n",
    "        self.image_path = image_path\n",
    "        self.chatbot = []\n",
    "        return \"Image uploaded successfully\"\n",
    "\n",
    "    def ask(self, question: str, num_beams: int = 1, temperature: float = 1.0) -> str:\n",
    "        if not self.image_path:\n",
    "            raise ValueError(\"No image uploaded. Call upload_image() first.\")\n",
    "        chat_in_path = self._to_json_file(self.chatbot if self.chatbot else [])\n",
    "        r1 = self.client.predict(question, chat_in_path, fn_index=1)\n",
    "        temp_chatbot = self._normalize_chatbot(r1[1])\n",
    "        r2 = self.client.predict(\n",
    "            self._to_json_file(temp_chatbot),\n",
    "            num_beams,\n",
    "            temperature,\n",
    "            fn_index=2,\n",
    "        )\n",
    "        self.chatbot = self._normalize_chatbot(r2)\n",
    "        if self.chatbot and isinstance(self.chatbot[-1], (list, tuple)) and len(self.chatbot[-1]) > 1:\n",
    "            return self.chatbot[-1][1] or \"\"\n",
    "        return \"\"\n",
    "\n",
    "    def chat(self, image_path: str, question: str, num_beams: int = 1, temperature: float = 1.0) -> str:\n",
    "        self.upload_image(image_path)\n",
    "        return self.ask(question, num_beams=num_beams, temperature=temperature)\n",
    "\n",
    "    def get_history(self) -> List[Tuple[str, Optional[str]]]:\n",
    "        return [(u, a) for u, a in self.chatbot] if isinstance(self.chatbot, list) else []\n",
    "\n",
    "    def reset(self):\n",
    "        self.chatbot = []\n",
    "        self.image_path = None\n",
    "        for p in self._tmp_files:\n",
    "            try:\n",
    "                os.remove(p)\n",
    "            except OSError:\n",
    "                pass\n",
    "        self._tmp_files.clear()"
   ],
   "id": "615a17e20090af43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "clint = MiniGPT4Client(\"https://3c3e6d00b6ef7beb73.gradio.live\")\n",
    "clint.chat(\"dataset/memes/image_211.jpg\", \"Can you explain this meme to me in short?\")"
   ],
   "id": "3970161b2c5a1524"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def worker(image_path: str, message: str) -> tuple[str, str]:\n",
    "    local_client = MiniGPT4Client(GRADIO_URL)\n",
    "    local_client.upload_image(image_path)\n",
    "    resp = local_client.ask(message, num_beams=1, temperature=1.0)\n",
    "    return image_path, resp"
   ],
   "id": "a50fac5099a831bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "questions = [\n",
    "    \"Explain why this meme is funny.\",\n",
    "    \"How should I make something like this?\",\n",
    "    \"Help me draft a professional advertisement for this.\",\n",
    "    \"Can you craft a beautiful poem about this image?\",\n",
    "]\n",
    "\n",
    "cocurrent_requests = 1\n",
    "responses = {}\n",
    "if os.path.exists(\"responses.json\"):\n",
    "    with open(\"responses.json\", \"r\") as f:\n",
    "        responses = json.load(f)\n",
    "for question in questions:\n",
    "    if question not in responses:\n",
    "        responses[question] = {}\n",
    "    tqdm.write(f\"Preparing storage for question: {question}\")\n",
    "    for category in ['mixed', 'memes', 'advertising', 'poems', 'recipie']:\n",
    "        tqdm.write(f\"  Category: {category}\")\n",
    "        if category not in responses[question]:\n",
    "            responses[question][category] = []\n",
    "        if category == 'mixed':\n",
    "            images = deepcopy(mixed_images)\n",
    "        elif category == 'memes':\n",
    "            images = deepcopy(meme_images)\n",
    "        elif category == 'advertising':\n",
    "            images = deepcopy(advertising_images)\n",
    "        elif category == 'poems':\n",
    "            images = deepcopy(poem_images)\n",
    "        elif category == 'recipie':\n",
    "            images = deepcopy(recipie_images)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown category: {category}\")\n",
    "        for img, _ in responses[question][category]:\n",
    "            if img in map(str, images):\n",
    "                images.remove(Path(img))\n",
    "        tqdm.write(f\"    {len(images)} images to process.\")\n",
    "        with ThreadPoolExecutor(max_workers=cocurrent_requests) as executor:\n",
    "            futures = {executor.submit(worker, str(img), question): img for img in images}\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing images for {category}\"):\n",
    "                img_path = futures[future]\n",
    "                try:\n",
    "                    img_path, response = future.result()\n",
    "                    responses[question][category].append((img_path, response))\n",
    "                    with open(f\"responses.json\", \"w\") as f:\n",
    "                        json.dump(responses, f, indent=4, ensure_ascii=False)\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f\"Error processing {img_path}: {e}\")"
   ],
   "id": "f9a4a804ede5fee6"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
